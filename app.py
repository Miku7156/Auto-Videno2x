import os
import subprocess
import configparser
import sys
import time
import logging
import json 
from datetime import datetime, timedelta
import re
import shutil
from collections import defaultdict
import threading
import time
            

# è§†é¢‘æ–‡ä»¶æ‰©å±•åé›†åˆ
VIDEO_EXTENSIONS = {'.mp4', '.mkv', '.avi', '.mov', '.flv', '.wmv', '.m4v', '.mpeg', '.mpg', '.ts', '.webm', '.vob', '.ogv', '.rmvb', '.asf', '.rm', '.3gp'}

# -------------------------------
# 1. æ—¥å¿—é…ç½®ï¼ˆåŠ¡å¿…æ”¾åœ¨æœ€å‰é¢ï¼‰
# -------------------------------

def get_base_dir():
    """è·å–åŸºç¡€ç›®å½•ï¼Œå…¼å®¹PyInstalleræ‰“åŒ…åçš„ç¯å¢ƒ"""
    if hasattr(sys, '_MEIPASS'):
        # æ‰“åŒ…åè¿”å›exeæ‰€åœ¨ç›®å½•
        return os.path.dirname(sys.executable)
    return os.path.dirname(os.path.abspath(__file__))

BASE_DIR = get_base_dir()

def setup_logging():
    log_dir = os.path.join(BASE_DIR, 'log')
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, 'app.log')

    # ä»é…ç½®æ–‡ä»¶è¯»å–æ—¥å¿—è¡Œæ•°é™åˆ¶
    config = configparser.ConfigParser()
    config.read('config.ini')
    max_log_lines = int(config.get('Logs', 'MaxLogLines', fallback=6000))
    if os.path.exists(log_file):
        with open(log_file, 'r', encoding='utf-8') as f:
            log_lines = f.readlines()
        if len(log_lines) > max_log_lines:
            with open(log_file, 'w', encoding='utf-8') as f:
                f.writelines(log_lines[-max_log_lines:])

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)  # å¯é€‰ï¼Œè°ƒè¯•ç”¨
        ]
    )

setup_logging()
logger = logging.getLogger(__name__)

# -------------------------------
# 2. åŸºç¡€è·¯å¾„ & é…ç½®è¯»å–
# -------------------------------
CONFIG_FILE = os.path.join(BASE_DIR, 'config.ini')
DATA_DIR = os.path.join(BASE_DIR, 'data')

config = configparser.ConfigParser()
config.read(CONFIG_FILE, encoding='utf-8')

scan_path = config.get('PATHS', 'ScanPath', fallback=None)

# è¯»å–è§†é¢‘å¤„ç†é…ç½®
# è¯»å–åˆ†è¾¨ç‡å¢å¼ºé…ç½®
res_width = config.get('ResolutionEnhancement', 'ResolutionWidth')
res_height = config.get('ResolutionEnhancement', 'ResolutionHeight')
res_processor = config.get('ResolutionEnhancement', 'Processor')
res_shader = config.get('ResolutionEnhancement', 'Shader')
# è¯»å–å¸§ç‡å¢å¼ºé…ç½®
frame_multiplier = config.get('FrameEnhancement', 'FrameMultiplier')
frame_processor = config.get('FrameEnhancement', 'Processor')
rife_model = config.get('FrameEnhancement', 'RifeModel')
tmp_dir = config.get('PATHS', 'TmpDir')
tmp_dir = os.path.join(BASE_DIR, tmp_dir)
os.makedirs(tmp_dir, exist_ok=True)

# è¯»å–video2xè·¯å¾„é…ç½®
video2x_path = config.get('PATHS', 'Video2xPath')
if not video2x_path or not os.path.exists(video2x_path):
    logger.error("âŒ è¯·åœ¨config.iniçš„[PATHS]èŠ‚ä¸­è®¾ç½®æœ‰æ•ˆçš„Video2xPathè·¯å¾„")
    sys.exit(1)

if not scan_path:
    logger.error("âŒ æœªåœ¨ config.ini çš„ [PATHS] èŠ‚ä¸­æ‰¾åˆ° ScanPath é…ç½®é¡¹")
    sys.exit(1)

if not os.path.exists(scan_path):
    logger.error("âŒ æ‰«æè·¯å¾„ä¸å­˜åœ¨: %s", scan_path)
    sys.exit(1)


# -------------------------------
# 3. æ¸…ç†è·¯å¾„ï¼Œç”Ÿæˆ JSON æ–‡ä»¶å
# -------------------------------
def sanitize_path_for_filename(path):
    folder_name = os.path.basename(os.path.normpath(path))
    return folder_name

sanitized_name = sanitize_path_for_filename(scan_path)
json_filename = f"scan_result_{sanitized_name}.json"
output_json_path = os.path.join(DATA_DIR, json_filename)

# -------------------------------
# 4. æ‰«æç›®å½•å¹¶è®°å½•æ—¥å¿—
# -------------------------------
file_data_list = []

logger.info(f"å¼€å§‹æ‰«æç›®å½•: {scan_path}")

try:
    for root, dirs, files in os.walk(scan_path):
        for file in files:
            # åªå¤„ç†è§†é¢‘æ–‡ä»¶
            ext = os.path.splitext(file)[1].lower()
            if ext not in VIDEO_EXTENSIONS:
                continue
            try:
                full_path = os.path.join(root, file)
                parent_dir = root
                filename_with_ext = file
                file_size = os.path.getsize(full_path)
                mod_time = os.path.getmtime(full_path)
                mod_time_str = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')

                # ä»æ–‡ä»¶åä¸­æå– å­£åº¦(S01) å’Œ é›†æ•°(E06)
                season_match = re.search(r'S(\d{2})E(\d{2,4})', filename_with_ext, re.IGNORECASE)
                season = "00"  # é»˜è®¤å€¼
                episode = "0000"  # é»˜è®¤å€¼

                if season_match:
                    season = season_match.group(1)  # å¦‚ '01'
                    episode = season_match.group(2)  # å¦‚ '06'

                file_record = {
                    "çˆ¶ç›®å½•": parent_dir,
                    "æ–‡ä»¶åå¸¦æ‰©å±•å": filename_with_ext,
                    "æ–‡ä»¶å®Œæ•´è·¯å¾„": full_path,
                    "æ–‡ä»¶å¤§å° (å­—èŠ‚)": file_size,
                    "æ–‡ä»¶ä¿®æ”¹æ—¶é—´": mod_time_str,
                    "å­£åº¦ä¿¡æ¯": season,
                    "é›†æ•°ä¿¡æ¯": episode,
                    "åˆ†æ”¯": -1,
                    "å¤„ç†ä¼˜å…ˆçº§": -1,
                    "å¤„ç†æ­¥éª¤": 3 if "Viden2x_HQ" in filename_with_ext else 0
                }
                file_data_list.append(file_record)
                logger.debug(f"å‘ç°è§†é¢‘æ–‡ä»¶: {file_record['æ–‡ä»¶å®Œæ•´è·¯å¾„']}")

            except Exception as e:
                logger.error("âš ï¸ å¤„ç†æ–‡ä»¶ '%s' æ—¶å‡ºé”™: %s", file, e, exc_info=True)

    logger.info(f"âœ… æ‰«æå®Œæˆï¼Œå…±å‘ç° {len(file_data_list)} ä¸ªè§†é¢‘æ–‡ä»¶")

    # æŒ‰ç›®å½•åˆ†ç»„æ–‡ä»¶
    dir_groups = {}
    for file in file_data_list:
        dir_path = file["çˆ¶ç›®å½•"]
        if dir_path not in dir_groups:
            dir_groups[dir_path] = []
        dir_groups[dir_path].append(file)

    # è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ (Levenshteinè·ç¦»)
    def levenshtein_distance(s1, s2):
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        if len(s2) == 0:
            return len(s1)
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        return previous_row[-1]

    # è£å‰ªæ–‡ä»¶ååˆ°ç›¸åŒé•¿åº¦ï¼Œä¿ç•™åç¼€å
    def trim_filenames(name1, name2):
        base1, ext1 = os.path.splitext(name1)
        base2, ext2 = os.path.splitext(name2)
        
        target_len = min(len(name1), len(name2))
        
        # å¤„ç†ç¬¬ä¸€ä¸ªæ–‡ä»¶å
        if len(name1) > target_len:
            base_len = target_len - len(ext1)
            base1 = base1[:base_len] if base_len > 0 else ''
            name1 = f"{base1}{ext1}"
        
        # å¤„ç†ç¬¬äºŒä¸ªæ–‡ä»¶å
        if len(name2) > target_len:
            base_len = target_len - len(ext2)
            base2 = base2[:base_len] if base_len > 0 else ''
            name2 = f"{base2}{ext2}"
        
        return name1, name2

    # å¤„ç†æ¯ä¸ªç›®å½•
    for dir_path, files in dir_groups.items():
        # 1. æ–‡ä»¶å½’ç±» (åˆ†æ”¯)
        branches = []
        ungrouped = [file for file in files if "Viden2x_HQ" not in file["æ–‡ä»¶å®Œæ•´è·¯å¾„"]]
        while ungrouped:
            current_file = ungrouped.pop(0)
            current_group = [current_file]
            current_name = current_file["æ–‡ä»¶åå¸¦æ‰©å±•å"]
            current_ext = os.path.splitext(current_name)[1]
            current_len = len(current_name)

            # æ¯”è¾ƒå‰©ä½™æ–‡ä»¶
            to_remove = []
            for i, file in enumerate(ungrouped):
                name = file["æ–‡ä»¶åå¸¦æ‰©å±•å"]
                ext = os.path.splitext(name)[1]
                name_len = len(name)

                # æ£€æŸ¥åç¼€åæ˜¯å¦ç›¸åŒ
                if ext != current_ext:
                    continue

                # æ£€æŸ¥æ–‡ä»¶åé•¿åº¦å·®å¼‚
                if abs(name_len - current_len) > 5:
                    continue

                # æ£€æŸ¥æ–‡ä»¶åç›¸ä¼¼åº¦
                # ç§»é™¤æ–‡ä»¶åä¸­çš„å­£åº¦å’Œé›†æ•°ä¿¡æ¯ (SxxExxæ ¼å¼)
                pattern = re.compile(r'S\d{2,}E\d{2,}', re.IGNORECASE)
                cleaned_current = pattern.sub('', current_name)
                cleaned_name = pattern.sub('', name) 
                distance = levenshtein_distance(cleaned_current, cleaned_name)
                similarity = 1 - (distance / max(len(current_name), len(name)))
                if similarity > 0.6:
                    current_group.append(file)
                    to_remove.append(i)

            # å°†åŒä¸€ç»„çš„æ–‡ä»¶æ ‡è®°ç›¸åŒåˆ†æ”¯
            branch_id = len(branches)
            for file in current_group:
                file["åˆ†æ”¯"] = branch_id
            branches.append(current_group)

            # ä»å¾…åˆ†ç»„åˆ—è¡¨ä¸­ç§»é™¤å·²åˆ†ç»„æ–‡ä»¶
            for i in reversed(to_remove):
                ungrouped.pop(i)

        # å¤„ç†å°åˆ†æ”¯åˆå¹¶ - å°†æ–‡ä»¶æ•°â‰¤2çš„åˆ†æ”¯åˆå¹¶åˆ°ç›¸ä¼¼åº¦æœ€é«˜çš„å¤§åˆ†æ”¯
        small_branches = [b for b in branches if len(b) <= 2]
        large_branches = [b for b in branches if len(b) >= 3]

        # ä»…å½“å­˜åœ¨å¤§åˆ†æ”¯æ—¶æ‰åˆå¹¶å°åˆ†æ”¯
        if large_branches and small_branches:
            # åˆ›å»ºæ–°åˆ†æ”¯åˆ—è¡¨ï¼Œä»¥å¤§åˆ†æ”¯ä¸ºåŸºç¡€
            new_branches = large_branches.copy()
            
            for small_branch in small_branches:
                # å–å°åˆ†æ”¯çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºä»£è¡¨
                small_rep = small_branch[0]
                small_name = small_rep["æ–‡ä»¶åå¸¦æ‰©å±•å"]
                min_distance = float('inf')
                best_branch = None

                # åœ¨æ–°åˆ†æ”¯åˆ—è¡¨ä¸­æ‰¾åˆ°ç›¸ä¼¼åº¦æœ€é«˜çš„å¤§åˆ†æ”¯ï¼ˆä¸è®¾ç½®åŒ¹é…é˜ˆå€¼ï¼‰
                for candidate_branch in new_branches:
                    # å–å€™é€‰åˆ†æ”¯çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºä»£è¡¨
                    rep_name = candidate_branch[0]["æ–‡ä»¶åå¸¦æ‰©å±•å"]
                     # è£å‰ªæ–‡ä»¶ååˆ°ç›¸åŒé•¿åº¦ï¼Œä¿ç•™åç¼€å
                    small_name_trimmed, rep_name_trimmed = trim_filenames(small_name, rep_name)
                     # è®¡ç®—è£å‰ªåçš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
                    distance = levenshtein_distance(small_name_trimmed, rep_name_trimmed)
                    if distance < min_distance:
                        min_distance = distance
                        best_branch = candidate_branch
                # å°†å°åˆ†æ”¯åˆå¹¶åˆ°æœ€ä½³åŒ¹é…çš„å¤§åˆ†æ”¯ï¼ˆä¸è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼ï¼‰
                # æ— æ¡ä»¶åˆå¹¶åˆ°æœ€ç›¸ä¼¼çš„å¤§åˆ†æ”¯
                branch_id = new_branches.index(best_branch)

                for file in small_branch:
                    file["åˆ†æ”¯"] = branch_id
                best_branch.extend(small_branch)
        
            # æ›´æ–°åˆ†æ”¯åˆ—è¡¨ä¸ºåˆå¹¶åçš„æ–°åˆ†æ”¯
            branches = new_branches

        # 2. è®¡ç®—å¤„ç†ä¼˜å…ˆçº§
        # 2.1 æ”¶é›†æ‰€æœ‰å­£åº¦å’Œé›†æ•°ç»„åˆ
        all_episodes = set()
        for file in files:
            if file["å­£åº¦ä¿¡æ¯"] != "00" and file["é›†æ•°ä¿¡æ¯"] != "00":
                all_episodes.add((file["å­£åº¦ä¿¡æ¯"], file["é›†æ•°ä¿¡æ¯"]))

        # 2.2 è®¡ç®—æ¯ä¸ªåˆ†æ”¯çš„æ–‡ä»¶å¤§å°æ€»å’Œ
        branch_sizes = defaultdict(int)
        for branch_id, branch_files in enumerate(branches):
            total_size = 0
            seen_episodes = set()
            for file in branch_files:
                # æ’é™¤åŒ…å«Viden2x_HQçš„æ–‡ä»¶
                if "Viden2x_HQ" in file["æ–‡ä»¶åå¸¦æ‰©å±•å"]:
                    continue
                episode_key = (file["å­£åº¦ä¿¡æ¯"], file["é›†æ•°ä¿¡æ¯"])
                # åªè®¡ç®—åœ¨æ‰€æœ‰åˆ†æ”¯ä¸­éƒ½å­˜åœ¨çš„å­£åº¦å’Œé›†æ•°ï¼Œä¸”æ¯ä¸ªé›†æ•°åªè®¡ç®—ä¸€æ¬¡
                if episode_key in all_episodes and episode_key not in seen_episodes:
                    # æ£€æŸ¥è¯¥å­£åº¦å’Œé›†æ•°æ˜¯å¦å­˜åœ¨äºæ‰€æœ‰åˆ†æ”¯
                    exists_in_all = True
                    for check_branch_id in range(len(branches)):
                        if check_branch_id == branch_id:
                            continue
                        found = False
                        for check_file in branches[check_branch_id]:
                            if (check_file["å­£åº¦ä¿¡æ¯"], check_file["é›†æ•°ä¿¡æ¯"]) == episode_key:
                                found = True
                                break
                        if not found:
                            exists_in_all = False
                            break
                    if exists_in_all:
                        total_size += file["æ–‡ä»¶å¤§å° (å­—èŠ‚)"]
                        seen_episodes.add(episode_key)
                    branch_sizes[branch_id] = total_size

        # 2.3 æŒ‰å¤§å°æ’åºåˆ†æ”¯å¹¶åˆ†é…ä¼˜å…ˆçº§
        # åˆ›å»ºåˆ†æ”¯IDåˆ°ç´¢å¼•çš„æ˜ å°„ï¼Œæé«˜æŸ¥æ‰¾æ•ˆç‡
        branch_index_map = {id(branch): idx for idx, branch in enumerate(branches)}
        # è¿‡æ»¤æ‰åˆ†æ”¯çº§ä¸º-1çš„åˆ†æ”¯
        filtered_branches = [branch for branch in branches if all(file["åˆ†æ”¯"] != -1 for file in branch)]
        sorted_branches = sorted(filtered_branches, key=lambda x: branch_sizes[branch_index_map[id(x)]])
        for priority, branch in enumerate(sorted_branches):
            for file in branch:
                file["å¤„ç†ä¼˜å…ˆçº§"] = priority

    logger.info(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(file_data_list)} ä¸ªæ–‡ä»¶")

    # æ–°æ—§æ‰«æç»“æœå¯¹æ¯”ï¼Œåªä¿ç•™æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶
    if os.path.exists(output_json_path):
        try:
            with open(output_json_path, 'r', encoding='utf-8') as f:
                old_data = json.load(f)
            # è¿‡æ»¤æ—§æ•°æ®ä¸­å®é™…æ–‡ä»¶ä¸å­˜åœ¨çš„æ¡ç›®
            old_data = [file for file in old_data if os.path.exists(file['æ–‡ä»¶å®Œæ•´è·¯å¾„'])]
            # åˆ›å»ºæ—§æ•°æ®çš„è·¯å¾„åˆ°æ–‡ä»¶ä¿¡æ¯çš„æ˜ å°„ï¼ˆç»Ÿä¸€è½¬ä¸ºå°å†™è·¯å¾„ï¼Œé¿å…å¤§å°å†™é—®é¢˜ï¼‰
            # åˆ›å»ºæ—§æ•°æ®çš„è·¯å¾„+å¤§å°ç»„åˆé”®æ˜ å°„ï¼ˆç”¨äºåˆ¤æ–­æ–°å¢æ–‡ä»¶ï¼‰
            old_file_keys = set()
            for file in old_data:
                path = file['æ–‡ä»¶å®Œæ•´è·¯å¾„'].lower()
                size = file['æ–‡ä»¶å¤§å° (å­—èŠ‚)']
                key = f"{path}_{size}"
                old_file_keys.add(key)
            
            # ç­›é€‰æ–°å¢æ–‡ä»¶ï¼ˆè·¯å¾„+å¤§å°ç»„åˆä¸å­˜åœ¨äºæ—§æ•°æ®ä¸­ï¼‰
            new_files = []
            for new_file in file_data_list:
                path = new_file['æ–‡ä»¶å®Œæ•´è·¯å¾„'].lower()
                size = new_file['æ–‡ä»¶å¤§å° (å­—èŠ‚)']
                key = f"{path}_{size}"
                if key not in old_file_keys:
                    new_files.append(new_file)
            
            # è¿½åŠ æ–°å¢æ–‡ä»¶åˆ°æ—§æ•°æ®ä¸­
            file_data_list = old_data + new_files
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"åŠ è½½æ—§æ‰«æç»“æœå¤±è´¥: {e}ï¼Œå°†ä¿å­˜å®Œæ•´æ‰«æç»“æœ")
            # åŠ è½½å¤±è´¥æ—¶ä½¿ç”¨å®Œæ•´æ‰«æç»“æœ
            pass

    os.makedirs(DATA_DIR, exist_ok=True)
    # ç­›é€‰6å¤©å†…æ›´æ–°ä¸”å¤„ç†ä¼˜å…ˆçº§==0ã€å¤„ç†æ­¥éª¤==0çš„æ–‡ä»¶ï¼Œæ ‡è®°å¤„ç†æ­¥éª¤ä¸º1ï¼ˆå·²ç­›é€‰ï¼‰
    current_time = datetime.now()
    six_days_ago = current_time - timedelta(days=6)
    filtered_count = 0
    filtered_files = []
    for file in file_data_list:
        if file.get("å¤„ç†ä¼˜å…ˆçº§") == 0 and file.get("å¤„ç†æ­¥éª¤") == 0:
            try:
                modify_time = datetime.strptime(file["æ–‡ä»¶ä¿®æ”¹æ—¶é—´"], '%Y-%m-%d %H:%M:%S')
                if modify_time >= six_days_ago:
                    file["å¤„ç†æ­¥éª¤"] = 1  # æ ‡è®°ä¸ºå·²ç­›é€‰
                    filtered_count += 1
                    filtered_files.append(file["æ–‡ä»¶å®Œæ•´è·¯å¾„"])
            except ValueError:
                logger.warning(f"æ— æ³•è§£ææ–‡ä»¶ä¿®æ”¹æ—¶é—´: {file['æ–‡ä»¶ä¿®æ”¹æ—¶é—´']}")
    # è¾“å‡ºç­›é€‰ç»“æœç»Ÿè®¡
    logger.info(f"ç­›é€‰å‡º {filtered_count} ä¸ªç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶:")
    for file_path in filtered_files:
        logger.info(f"- {file_path}")
    
    # è¯»å–åˆ†è¾¨ç‡å¢å¼ºå€æ•°é…ç½®
    res_multiplier = config.get('Video', 'res_multiplier', fallback='2')
    # å¼€å§‹ç”»é¢å¢å¼ºå¤„ç†
    # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„æ—¶é—´èŒƒå›´å†…æ‰§è¡Œ
    allowed_days = config.get('Schedule', 'AllowedDays', fallback='1-7')
    start_day, end_day = map(int, allowed_days.split('-'))
    current_day = datetime.now().weekday() + 1  # Pythonä¸­å‘¨ä¸€ä¸º0ï¼Œè½¬æ¢ä¸º1-7

    if not (start_day <= current_day <= end_day):
        logger.info(f"å½“å‰æ˜ŸæœŸ {current_day} ä¸åœ¨å…è®¸çš„æ‰§è¡Œæ—¶é—´èŒƒå›´ {allowed_days} å†…ï¼Œä¿å­˜æ•°æ®å¹¶é€€å‡ºç¨‹åº")
        # ä¿å­˜æ•°æ®
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(file_data_list, f, ensure_ascii=False, indent=2)
        logger.info("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: %s", output_json_path)
        sys.exit(0)
    
    # æ£€æŸ¥GPUå ç”¨åº¦
    gpu_threshold = config.getint('Schedule', 'GpuUsageThreshold', fallback=80)
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'],
            capture_output=True, text=True, check=True
        )
        gpu_usage = int(result.stdout.strip())
        logger.info(f"å½“å‰GPUä½¿ç”¨ç‡: {gpu_usage}%")

        if gpu_usage > gpu_threshold:
            logger.info(f"GPUå ç”¨åº¦ {gpu_usage}% è¶…è¿‡é˜ˆå€¼ {gpu_threshold}%ï¼Œä¿å­˜æ•°æ®å¹¶é€€å‡ºç¨‹åº")
            # ä¿å­˜æ•°æ®
            with open(output_json_path, 'w', encoding='utf-8') as f:
                json.dump(file_data_list, f, ensure_ascii=False, indent=2)
            logger.info("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: %s", output_json_path)
            sys.exit(0)
    except subprocess.CalledProcessError as e:
        logger.warning(f"è·å–GPUä½¿ç”¨ç‡å¤±è´¥: {e}ï¼Œå°†ç»§ç»­æ‰§è¡Œç¨‹åº")
    except (ValueError, Exception) as e:
        logger.warning(f"GPUæ£€æŸ¥å¼‚å¸¸: {e}ï¼Œå°†ç»§ç»­æ‰§è¡Œç¨‹åº")

    #  è¿›è¡Œç”»é¢å¢å¼ºå¤„ç†
    for file in file_data_list:
        if file.get("å¤„ç†æ­¥éª¤") == 1:
            input_path = file["æ–‡ä»¶å®Œæ•´è·¯å¾„"]
            filename = os.path.basename(input_path)
            output_path = os.path.join(tmp_dir, filename)
            logger.info(f"å¼€å§‹å¢å¼ºç”»é¢: {input_path}")
            # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
            def loading_animation(stop_event):
                while not stop_event.is_set():
                    for char in '|/-\ ':
                        print(f'\ræ­£åœ¨å¢å¼ºç”»é¢ä¸­... {char}', end='', flush=True)
                        time.sleep(0.1)
                print('\rå¢å¼ºç”»é¢å®Œæˆ!        ', flush=True)
            
            stop_event = threading.Event()
            loading_thread = threading.Thread(target=loading_animation, args=(stop_event,))
            loading_thread.start()
            try:
                start_time = time.time()
                subprocess.run([
                    video2x_path,
                    '-i', input_path,
                    '-o', output_path,
                    '-w', res_width,
                    '-h', res_height,
                    '-p', res_processor,
                    '--libplacebo-shader', res_shader
                ], capture_output=True, text=True)
                end_time = time.time()
                duration = end_time - start_time
                logger.info(f"ç”»é¢å¢å¼ºå®Œæˆ:{output_path},è€—æ—¶: {duration:.2f}ç§’")
                file['å¤„ç†æ­¥éª¤'] = 2  # æ ‡è®°ä¸ºå·²å¢å¼º
                #ä¿å­˜æ•°æ®
                with open(output_json_path, 'w', encoding='utf-8') as f:
                    json.dump(file_data_list, f, ensure_ascii=False, indent=2)
                logger.info("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: %s", output_json_path)
            except subprocess.CalledProcessError as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {input_path} å¤±è´¥: {e}")
            finally:
                stop_event.set()
                loading_thread.join()

        # å¸§ç‡å¢å¼ºå¤„ç†ï¼šå¤„ç†æ­¥éª¤=2çš„æ–‡ä»¶
        if file.get('å¤„ç†æ­¥éª¤') == 2:
            input_filename = os.path.basename(file['æ–‡ä»¶å®Œæ•´è·¯å¾„'])
            input_path = os.path.join(tmp_dir, input_filename)
            
            # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨å·²å¢å¼ºçš„æ–‡ä»¶
            if not os.path.exists(input_path):
                logger.warning(f"ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¸§ç‡å¢å¼º: {input_path}")
                continue
            
            # æ„å»ºæ–°æ–‡ä»¶å
            base_name, ext = os.path.splitext(input_filename)
            new_filename = f"{base_name} {res_width}x{res_height} fpsx{frame_multiplier} Viden2x_HQ{ext}"
            output_path = os.path.join(tmp_dir, new_filename)
            
            try:
                logger.info(f"å¼€å§‹å¸§ç‡å¢å¼º: {input_path}")
                start_time = time.time()
                # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
                def loading_animation(stop_event):
                    while not stop_event.is_set():
                        for char in '|/-\ ':
                            print(f'\ræ­£åœ¨å¢å¼ºå¸§ç‡ä¸­... {char}', end='', flush=True)
                            time.sleep(0.1)
                    print('\rå¢å¼ºå¸§ç‡å®Œæˆ!        ', flush=True)
                stop_event = threading.Event()
                loading_thread = threading.Thread(target=loading_animation, args=(stop_event,))
                loading_thread.start()
                # æ‰§è¡Œvideo2xå¸§ç‡å¢å¼ºå‘½ä»¤
                # æ·»åŠ è¯¦ç»†æ—¥å¿—å’Œé”™è¯¯æ•è·
                result = subprocess.run([
                    video2x_path,
                    'upscale',  # æ˜¾å¼æŒ‡å®šupscaleå‘½ä»¤
                    '-i', input_path,
                    '-o', output_path,
                    '-m', frame_multiplier,
                    '-p', frame_processor,
                    '--rife-model', rife_model,
                ], capture_output=True, text=True)
                # å¤„ç†è¾“å‡ºå†…å®¹ï¼ŒåŒºåˆ†GPUä¿¡æ¯å’Œé”™è¯¯
                stderr_lines = result.stderr.splitlines()
                gpu_lines = [line for line in stderr_lines if '[0 NVIDIA GeForce' in line]
                non_gpu_lines = [line for line in stderr_lines if '[0 NVIDIA GeForce' not in line and line.strip()]
                # æ£€æŸ¥å‘½ä»¤æ‰§è¡Œç»“æœ
                if result.returncode == 0:
                    # å‘½ä»¤æˆåŠŸæ‰§è¡Œ
                    if non_gpu_lines:
                        logger.warning(f"å¸§ç‡å¢å¼ºæˆåŠŸä½†å­˜åœ¨è¾“å‡º: {chr(10).join(non_gpu_lines)}")
                    # è®¡ç®—å¤„ç†æ—¶é—´
                    end_time = time.time()
                    stop_event.set()
                    loading_thread.join()
                    duration = end_time - start_time
                    logger.info(f"å¸§ç‡å¢å¼ºå®Œæˆ:{output_path},è€—æ—¶: {duration:.2f}ç§’")
                    file['å¤„ç†æ­¥éª¤'] = 3    #æ ‡è®°ä¸ºå·²æ‰§è¡Œå®Œå…¨éƒ¨å¤„ç†
                    # éªŒè¯è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§
                    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                        logger.info(f"å¸§ç‡å¢å¼ºæ–‡ä»¶éªŒè¯æˆåŠŸ: {output_path}")
                        # å°†æ–‡ä»¶ç§»åŠ¨åˆ°åŸæ–‡ä»¶ç›®å½•
                        original_dir = os.path.dirname(file['æ–‡ä»¶å®Œæ•´è·¯å¾„'])
                        target_path = os.path.join(original_dir, new_filename)
                        try:
                            os.makedirs(original_dir, exist_ok=True)
                            shutil.move(output_path, target_path)
                            logger.info(f"å¸§ç‡å¢å¼ºæ–‡ä»¶å·²ç§»åŠ¨è‡³: {target_path}")
                            # æ›´æ–°æ–‡ä»¶è®°å½•è·¯å¾„å’Œå¤„ç†çŠ¶æ€
                            file['å¤„ç†æ­¥éª¤'] = 3  # æ ‡è®°ä¸ºå·²å®Œæˆæ‰€æœ‰å¤„ç†
                            # æ¸…ç†ä¸´æ—¶ç”»é¢å¢å¼ºæ–‡ä»¶
                            if os.path.exists(input_path):
                                os.remove(input_path)
                                logger.info(f"å·²æ¸…ç†ä¸´æ—¶ç”»é¢å¢å¼ºæ–‡ä»¶: {input_path}")
                        except Exception as e:
                            logger.error(f"æ–‡ä»¶ç§»åŠ¨æˆ–æ¸…ç†å¤±è´¥: {str(e)}")
                    else:
                        logger.error(f"å¸§ç‡å¢å¼ºæ–‡ä»¶éªŒè¯å¤±è´¥: {output_path} ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                        file['å¤„ç†æ­¥éª¤'] = 2  # é‡ç½®å¤„ç†æ­¥éª¤ä»¥ä¾¿é‡è¯•
                else:
                    # å‘½ä»¤è¿”å›éé›¶é€€å‡ºç 
                    if not non_gpu_lines and gpu_lines:
                        # ä»…åŒ…å«GPUä¿¡æ¯ï¼Œè§†ä¸ºæˆåŠŸ
                        # è®¡ç®—å¤„ç†æ—¶é—´
                        end_time = time.time()
                        duration = end_time - start_time
                        logger.info(f"å¸§ç‡å¢å¼ºå®Œæˆ:{output_path},è€—æ—¶: {duration:.2f}ç§’")
                        file['å¤„ç†æ­¥éª¤'] = 3   #æ ‡è®°ä¸ºå·²æ‰§è¡Œå®Œå…¨éƒ¨å¤„ç†
                        # éªŒè¯è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§
                        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                            logger.info(f"å¸§ç‡å¢å¼ºæ–‡ä»¶éªŒè¯æˆåŠŸ: {output_path}")
                            # å°†æ–‡ä»¶ç§»åŠ¨åˆ°åŸæ–‡ä»¶ç›®å½•
                            original_dir = os.path.dirname(file['æ–‡ä»¶å®Œæ•´è·¯å¾„'])
                            target_path = os.path.join(original_dir, new_filename)
                            try:
                                os.makedirs(original_dir, exist_ok=True)
                                shutil.move(output_path, target_path)
                                logger.info(f"å¸§ç‡å¢å¼ºæ–‡ä»¶å·²ç§»åŠ¨è‡³: {target_path}")
                                # æ›´æ–°æ–‡ä»¶è®°å½•è·¯å¾„å’Œå¤„ç†çŠ¶æ€
                                file['å¤„ç†æ­¥éª¤'] = 3  # æ ‡è®°ä¸ºå·²å®Œæˆæ‰€æœ‰å¤„ç†
                                # æ¸…ç†ä¸´æ—¶ç”»é¢å¢å¼ºæ–‡ä»¶
                                if os.path.exists(input_path):
                                    os.remove(input_path)
                                    logger.info(f"å·²æ¸…ç†ä¸´æ—¶ç”»é¢å¢å¼ºæ–‡ä»¶: {input_path}")
                            except Exception as e:
                                logger.error(f"æ–‡ä»¶ç§»åŠ¨æˆ–æ¸…ç†å¤±è´¥: {str(e)}")
                        else:
                            logger.error(f"å¸§ç‡å¢å¼ºæ–‡ä»¶éªŒè¯å¤±è´¥: {output_path} ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                            file['å¤„ç†æ­¥éª¤'] = 2  # é‡ç½®å¤„ç†æ­¥éª¤ä»¥ä¾¿é‡è¯•
                    else:
                        # çœŸæ­£çš„é”™è¯¯ï¼Œè®°å½•å¹¶æŠ›å‡ºå¼‚å¸¸
                        logger.error(f"å¸§ç‡å¢å¼ºå¤±è´¥: é€€å‡ºä»£ç  {result.returncode}, å‘½ä»¤: {result.args}")
                        if result.stdout:
                            logger.error(f"æ ‡å‡†è¾“å‡º: {result.stdout}")
                        if non_gpu_lines:
                            logger.error(f"é”™è¯¯è¾“å‡º: {chr(10).join(non_gpu_lines)}")
                        else:
                            logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                        raise subprocess.CalledProcessError(result.returncode, result.args)
            except subprocess.CalledProcessError as e:
                logger.error(f"å¸§ç‡å¢å¼ºå¤±è´¥: é€€å‡ºä»£ç  {e.returncode}, å‘½ä»¤: {e.cmd}")
                logger.error(f"æ ‡å‡†è¾“å‡º: {getattr(e, 'stdout', 'æœªæ•è·')}")
                logger.error(f"é”™è¯¯è¾“å‡º: {getattr(e, 'stderr', 'æœªæ•è·')}")
            except Exception as e:
                logger.error(f"å¸§ç‡å¢å¼ºå‘ç”Ÿå¼‚å¸¸: {str(e)}")

            finally:
                stop_event.set()
                loading_thread.join()
    #ä¿å­˜æ•°æ®
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(file_data_list, f, ensure_ascii=False, indent=2)
    logger.info("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: %s", output_json_path)
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨å…³æœº
    auto_shutdown = config.getboolean('Schedule', 'AutoShutdown', fallback=False)
    if auto_shutdown:
        logger.info("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œå‡†å¤‡å…³é—­ç”µè„‘...")
        subprocess.run(["powershell", "Stop-Computer", "-Force"])
        sys.exit(0)
    else:
        logger.info("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œè‡ªåŠ¨å…³æœºåŠŸèƒ½å·²ç¦ç”¨")
        sys.exit(0)

except Exception as e:
    logger.critical("ğŸ’¥ æ‰«æè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: %s", e, exc_info=True)
    sys.exit(1)
